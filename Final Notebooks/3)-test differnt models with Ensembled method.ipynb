{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72989a5",
   "metadata": {},
   "source": [
    "# Title: Project ML:  Fraud Detection for Online Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f99f08a",
   "metadata": {},
   "source": [
    "##### The project follow following steps \n",
    "1) Data Collection  \n",
    "2) Data Cleaning and Preprocessing  \n",
    "3) Visualize the Data  \n",
    "4) Split the Data  \n",
    "5) Label encoding  \n",
    "6) Model Training  \n",
    "7) Model Evaluation  \n",
    "8) Optimize the Model  \n",
    "9) Web Application Development  \n",
    "10) Deployment and Group Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a1cf8",
   "metadata": {},
   "source": [
    "## 1) Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d5fa5",
   "metadata": {},
   "source": [
    "# 4) Split the Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e35efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3945bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "clean_train_data = pd.read_csv(\"Resources/clean_train_data.csv\")\n",
    "clean_test_data = pd.read_csv(\"Resources/clean_test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d465d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target in the train data\n",
    "# Separate the target variable (isFraud) from the features\n",
    "X = clean_train_data.drop(\"isFraud\", axis=1)\n",
    "y= clean_train_data[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d345844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2b8b3",
   "metadata": {},
   "source": [
    "## 5) Label encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5565a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to apply label encoding to all categorical columns\n",
    "def label_encode(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            label_encoder = LabelEncoder()\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "    return df\n",
    "\n",
    "# Apply label encoding to the train and test data\n",
    "X_train = label_encode(X_train)\n",
    "X_test = label_encode(X_test)\n",
    "\n",
    "# Train and evaluate your model\n",
    "# (your code for training and evaluating the AdaBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad39b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb8c79",
   "metadata": {},
   "source": [
    "##  6) Model Training  by using RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e85908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=50).fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2520e3f",
   "metadata": {},
   "source": [
    "## 7) Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050642ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8c095",
   "metadata": {},
   "source": [
    "## 8)   Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2603e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an AdaBoostClassifier with base_estimator set as DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "clf_ada = AdaBoostClassifier(random_state=1, n_estimators=50, base_estimator=DecisionTreeClassifier(max_depth=2)).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Check the performance of the AdaBoostClassifier\n",
    "print(f'AdaBoost Training Score: {clf_ada.score(X_train_scaled, y_train)}')\n",
    "print(f'AdaBoost Testing Score: {clf_ada.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfecda05",
   "metadata": {},
   "source": [
    "## 9) Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3eb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Training Score: 0.999778733588467\n",
      "Testing Score: 0.9801469841162326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    142497\n",
      "           1       0.93      0.47      0.62      5138\n",
      "\n",
      "    accuracy                           0.98    147635\n",
      "   macro avg       0.95      0.73      0.80    147635\n",
      "weighted avg       0.98      0.98      0.98    147635\n",
      "\n",
      "\n",
      "Extremely Random Trees Classifier:\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.9809462525823822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    142497\n",
      "           1       0.92      0.50      0.65      5138\n",
      "\n",
      "    accuracy                           0.98    147635\n",
      "   macro avg       0.95      0.75      0.82    147635\n",
      "weighted avg       0.98      0.98      0.98    147635\n",
      "\n",
      "\n",
      "AdaBoost Classifier:\n",
      "Training Score: 0.9705106061119202\n",
      "Testing Score: 0.9705760829071697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98    142497\n",
      "           1       0.82      0.20      0.32      5138\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.90      0.60      0.65    147635\n",
      "weighted avg       0.97      0.97      0.96    147635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1, n_estimators=50).fit(X_train_scaled, y_train)\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(f'Training Score: {rfc.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {rfc.score(X_test_scaled, y_test)}')\n",
    "y_pred_rfc = rfc.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_rfc))\n",
    "\n",
    "# Train an ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(random_state=1, n_estimators=50).fit(X_train_scaled, y_train)\n",
    "print(\"\\nExtremely Random Trees Classifier:\")\n",
    "print(f'Training Score: {etc.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {etc.score(X_test_scaled, y_test)}')\n",
    "y_pred_etc = etc.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_etc))\n",
    "\n",
    "# Train an AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(random_state=1, n_estimators=50).fit(X_train_scaled, y_train)\n",
    "print(\"\\nAdaBoost Classifier:\")\n",
    "print(f'Training Score: {abc.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {abc.score(X_test_scaled, y_test)}')\n",
    "y_pred_abc = abc.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2399813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e981ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest classifier with default hyperparameters\n",
    "rfc = RandomForestClassifier(random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GridSearchCV to search over the parameter grid and find the best hyperparameters\n",
    "grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=5, n_jobs=-1, scoring='f1')\n",
    "grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters and the corresponding F1 score on the validation set\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Validation F1 score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the best model on the testing set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_f1_score = cross_val_score(best_model, X_test_scaled, y_test, cv=5, scoring='f1').mean()\n",
    "print(f\"Testing F1 score: {test_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717ee64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ae907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c943615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
