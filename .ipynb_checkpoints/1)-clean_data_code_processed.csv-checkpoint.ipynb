{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6e8fbd",
   "metadata": {},
   "source": [
    "# Title: Project ML:  Fraud Detection for Online Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f4c0f",
   "metadata": {},
   "source": [
    "##### The project follow following steps \n",
    "1) Data Collection  \n",
    "2) Data Cleaning and Preprocessing\n",
    "3) Visualize the Data  \n",
    "4) Split the Data  \n",
    "5) Label encoding  \n",
    "6) Model Training  \n",
    "7) Model Evaluation  \n",
    "8) Optimize the Model  \n",
    "9) Web Application Development  \n",
    "10) Deployment and Group Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3afaaf",
   "metadata": {},
   "source": [
    "## 1) Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50870e96",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/ieee-fraud-detection/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08017277",
   "metadata": {},
   "source": [
    "## 2) Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de14588",
   "metadata": {},
   "source": [
    "#### Step 1: Load required libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b80759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855db98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path1 = Path(\"Resources/test_identity.csv\")\n",
    "file_path2 = Path(\"Resources/test_transaction.csv\")\n",
    "file_path3 = Path(\"Resources/train_identity.csv\")\n",
    "file_path4 = Path(\"Resources/train_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "test_identity = pd.read_csv(file_path1)\n",
    "test_transaction = pd.read_csv(file_path2)\n",
    "train_identity = pd.read_csv(file_path3)\n",
    "train_transaction = pd.read_csv(file_path4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc484e7a",
   "metadata": {},
   "source": [
    "### Note: \n",
    "\n",
    "**The dataset contains information about the identity and transactions made by the individuals in train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80f58b",
   "metadata": {},
   "source": [
    "#### Step 2: Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4eb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shape of the data\n",
    "print(\"test_identity Shape: \", test_identity.shape)\n",
    "print(\"test_transaction Shape: \", test_transaction.shape)\n",
    "print(\"train_identity Shape: \", train_identity.shape)\n",
    "print(\"train_transaction Shape: \", train_transaction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ddb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first two rows of each dataset\n",
    "print(test_identity.head())\n",
    "print(test_transaction.head())\n",
    "print(train_identity.head())\n",
    "print(train_transaction.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca59ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about the data\n",
    "print(test_identity.info())\n",
    "print(test_transaction.info())\n",
    "print(train_identity.info())\n",
    "print(train_transaction.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c05a8",
   "metadata": {},
   "source": [
    "### Note:  \n",
    "\n",
    "**The train and test datasets have a column `TransactionID`, which can be used as the unique identifier for each transaction.\n",
    "\n",
    "**The transaction files contain information such as transaction amount, time, and card information, while the identity files contain information such as device type, device info, and several ID columns.**\n",
    "\n",
    "**The train dataset has a target column called `isFraud`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0386f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get descriptive statistics for each dataset\n",
    "print(test_identity.describe())\n",
    "print(test_transaction.describe())\n",
    "print(train_identity.describe())\n",
    "print(train_transaction.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb38984",
   "metadata": {},
   "source": [
    "#### Step 3:  Duplicate  Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f579491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Duplicate Values:\n",
    "test_identity.duplicated().sum()\n",
    "test_transaction.duplicated().sum()\n",
    "train_identity.duplicated().sum()\n",
    "train_transaction.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992be996",
   "metadata": {},
   "source": [
    "#### Step 4:Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89cd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge identity and transaction datasets\n",
    "train = train_transaction.merge(train_identity, on=\"TransactionID\", how=\"left\")\n",
    "test = test_transaction.merge(test_identity, on=\"TransactionID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the merged data\n",
    "print(\"train_data Shape: \", train.shape)\n",
    "print(\"test_data Shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa29a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in train and test data\n",
    "missing_train = train.isnull().sum().sort_values(ascending=False)\n",
    "missing_test = test.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedda853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the percentage of missing values in each column\n",
    "print(\"Missing values in train (%):\")\n",
    "print((missing_train / len(train)) * 100)\n",
    "print(\"\\nMissing values in test_data (%):\")\n",
    "print((missing_test / len(test)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2516bb",
   "metadata": {},
   "source": [
    "### Note:\n",
    "**drop columns with a missing value percentage greater than a certain threshold (let's say 50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3a3b7",
   "metadata": {},
   "source": [
    "#### Step 5: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 40% missing values\n",
    "train_data = train.drop(columns=missing_train[missing_train > 0.40 * len(train)].index)\n",
    "test_data = test.drop(columns=missing_test[missing_test > 0.40 * len(test)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0935a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in the remaining columns with their respective means\n",
    "train_data.fillna(train_data.mean(), inplace=True)\n",
    "test_data.fillna(test_data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinity values with NaN\n",
    "train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN values with the mean of each column\n",
    "train_data.fillna(train_data.mean(), inplace=True)\n",
    "test_data.fillna(test_data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7be7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6a9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580df560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(columns=[\"isFraud\"]), train_data[\"isFraud\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d744cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode categorical variables\n",
    "le = LabelEncoder()\n",
    "categorical_cols = [\"ProductCD\", \"card4\", \"card6\", \"P_emaildomain\", \"R_emaildomain\"]\n",
    "for col in categorical_cols:\n",
    "    X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "    X_test[col] = le.transform(X_test[col].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578027e",
   "metadata": {},
   "source": [
    "#### Step 6:Save cleaned data to new CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to new CSV files\n",
    "X_train.to_csv(\"Resources/clean_train_data.csv\", index=False)\n",
    "X_test.to_csv(\"Resources/clean_test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211342dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25895bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# Create an SQLite database\n",
    "engine = create_engine('postgresql://postgres:3720@localhost:5432/Fraud-detection')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b289524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save cleaned data to the SQLite database\n",
    "# train_data.to_sql('clean_train_data', engine, index=False, if_exists='replace')\n",
    "# test_data.to_sql('clean_test_data', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f01d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythonData] *",
   "language": "python",
   "name": "conda-env-pythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
